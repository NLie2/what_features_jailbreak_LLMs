{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paths initialized successfully. You can now use PROJECT_ROOT, DATASETS_DIR, etc.\n"
     ]
    }
   ],
   "source": [
    "# Import the init_paths module\n",
    "from init_paths import (\n",
    "    PROJECT_ROOT,\n",
    "    DATASETS_DIR,\n",
    "    ANALYSIS_DIR,\n",
    "    EXPERIMENTS_DIR,\n",
    "    IMAGES_DIR,\n",
    "    GEN_DATA_DIR,\n",
    "    LOGS_DIR,\n",
    "    get_project_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis.supervised import *\n",
    "from analysis.models import * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_meta-llamaLlama-3.1-8B-Instruct_prompt_res_activations_2102202513:10:37_rated.pkl\n"
     ]
    }
   ],
   "source": [
    "publication = [\"public_1\", \"public_2\"][1]\n",
    "\n",
    "folder_path = DATASETS_DIR / f\"prompt_activations/{publication}/\"\n",
    "files = os.listdir(folder_path)\n",
    "\n",
    "models_list = list(models.keys())\n",
    "model = models_list[1]\n",
    "\n",
    "for file in files:\n",
    "    \n",
    "    if file.endswith(\".pkl\") and \"rated\" in file and model in file: \n",
    "      print(file)\n",
    "      path = folder_path / file\n",
    "\n",
    "      df = pd.read_pickle(path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating_binary\n",
       "1    3633\n",
       "0    3633\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name, num_layers, rating_column, hf_ident, input_size = get_model_details(path)\n",
    "\n",
    "layer= num_layers - 4\n",
    "\n",
    "# layer = 17\n",
    "activation_column=\"prompt_res_activations\"\n",
    "num_samples = len(df)\n",
    "dataset_name = \"wildJailBreak\" if \"wildJailBreak\" in str(path) else \"wei_dataset\"\n",
    "\n",
    "df[\"rating_binary\"] = df[rating_column].apply(lambda x: 0 if x == \"No\" else 1)\n",
    "df = df[~df[\"jailbreak_prompt_name\"].isin([\"auto_payload_splitting\", \"auto_obfuscation\", \"dev_mode_with_rant\", \"gcg\", \"autodan\"])]\n",
    "df[\"jailbreak_prompt_name\"].value_counts()\n",
    "#shuffle and balance dataset\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "df = balance_dataset(df, \"rating_binary\")\n",
    "df[\"rating_binary\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data_and_labels(df, layers, filepath):\n",
    "    \"\"\"\n",
    "    Prepare data by extracting features, melting the dataframe, and splitting into train/val sets.\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame containing the data\n",
    "        layers (list): List of layers to extract features from\n",
    "        filepath (str): Path to save the tensors and CSV\n",
    "    \"\"\"\n",
    "    # Extract features for each layer\n",
    "    for layer in layers:\n",
    "        df[f'layer_{layer}'] = df.apply(lambda row: extract_layer(row, layer), axis=1)\n",
    "    \n",
    "    # Store original DataFrame before melting for CSV export\n",
    "    df_for_csv = df.copy()\n",
    "    \n",
    "    # Melt the DataFrame\n",
    "    melted_df = pd.melt(\n",
    "        df,\n",
    "        id_vars=[\"jailbreak_prompt_name\", \"rating_binary\"],\n",
    "        value_vars=[f'layer_{layer}' for layer in layers],\n",
    "        var_name=\"layer\",\n",
    "        value_name=\"features\"\n",
    "    )\n",
    "    \n",
    "    # Prepare labels and data\n",
    "    labels = melted_df[\"rating_binary\"].to_list()\n",
    "    data = melted_df[\"features\"].to_list()\n",
    "    \n",
    "    # Convert to tensors\n",
    "    data_tensor = torch.tensor(np.stack(data), dtype=torch.float32)\n",
    "    labels_tensor = torch.tensor(labels, dtype=torch.long)\n",
    "    \n",
    "    # Save tensors\n",
    "    dataset_dict = {\n",
    "        'data': data_tensor,\n",
    "        'labels': labels_tensor\n",
    "    }\n",
    "    torch.save(dataset_dict, filepath)\n",
    "    \n",
    "    # Save CSV without tensor columns\n",
    "    tensor_cols = ['prompt_res_activations'] + [f'layer_{i}' for i in layers]\n",
    "    df_for_csv_no_tensors = df_for_csv.drop(tensor_cols, axis=1)\n",
    "    df_for_csv_no_tensors.to_csv(filepath.replace(\".pt\", \".csv\"), index=True)\n",
    "\n",
    "filepath = f\"{path}_tensors.pt\"\n",
    "layers = range(0, num_layers)\n",
    "save_data_and_labels(df, layers, filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3227610/31292468.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_data = torch.load(filepath)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data tensor shape: torch.Size([261576, 4096])\n",
      "Labels tensor shape: torch.Size([261576])\n"
     ]
    }
   ],
   "source": [
    "# Test if your tensor saving worked\n",
    "\n",
    "# Load the saved tensor data\n",
    "loaded_data = torch.load(filepath)\n",
    "\n",
    "# Extract data and labels from the loaded dictionary\n",
    "data_tensor = loaded_data['data']\n",
    "labels_tensor = loaded_data['labels']\n",
    "\n",
    "# Print shapes to verify the loading\n",
    "print(f\"Data tensor shape: {data_tensor.shape}\")\n",
    "print(f\"Labels tensor shape: {labels_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded CSV info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 7266 entries, 0 to 7265\n",
      "Data columns (total 7 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   prompt_name            7266 non-null   object\n",
      " 1   jailbreak_prompt_name  7266 non-null   object\n",
      " 2   jailbreak_prompt_text  7266 non-null   object\n",
      " 3   original_prompt_text   7266 non-null   object\n",
      " 4   output_text            7265 non-null   object\n",
      " 5   rating_output_text     7266 non-null   object\n",
      " 6   rating_binary          7266 non-null   int64 \n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 454.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Load the saved CSV data\n",
    "csv_filepath = filepath.replace(\".pt\", \".csv\")\n",
    "df_loaded = pd.read_csv(csv_filepath, index_col=0)\n",
    "\n",
    "# Print info to verify loading\n",
    "print(\"\\nLoaded CSV info:\")\n",
    "print(df_loaded.info())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
